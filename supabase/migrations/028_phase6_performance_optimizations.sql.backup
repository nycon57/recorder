-- ============================================
-- PHASE 6: PERFORMANCE OPTIMIZATIONS
-- Optimizations for quota checks, caching, and analytics
-- ============================================

-- ============================================
-- OPTIMIZED QUOTA CHECK FUNCTION
-- ============================================

-- Optimized quota check function with SKIP LOCKED to avoid contention
CREATE OR REPLACE FUNCTION check_quota_optimized(
  p_org_id UUID,
  p_quota_type TEXT,
  p_amount INTEGER DEFAULT 1
) RETURNS BOOLEAN AS $$
DECLARE
  v_quota org_quotas%ROWTYPE;
  v_available INTEGER;
BEGIN
  -- Use SKIP LOCKED to avoid blocking on locked rows
  SELECT * INTO v_quota FROM org_quotas
  WHERE org_id = p_org_id
  FOR UPDATE SKIP LOCKED;

  -- If row is locked, fail fast
  IF NOT FOUND THEN
    -- Try read-only check as fallback
    SELECT * INTO v_quota FROM org_quotas WHERE org_id = p_org_id;
    IF NOT FOUND THEN
      RAISE EXCEPTION 'Quota not found for org %', p_org_id;
    END IF;
    -- Return false if we can't get lock (conservative approach)
    RETURN FALSE;
  END IF;

  -- Check if quota needs reset
  IF v_quota.quota_reset_at < now() THEN
    UPDATE org_quotas SET
      searches_used = 0,
      recordings_used = 0,
      ai_requests_used = 0,
      quota_reset_at = date_trunc('month', now()) + INTERVAL '1 month'
    WHERE org_id = p_org_id;

    -- Re-fetch after reset
    SELECT * INTO v_quota FROM org_quotas WHERE org_id = p_org_id;
  END IF;

  -- Check available quota based on type
  CASE p_quota_type
    WHEN 'search' THEN
      v_available := v_quota.searches_per_month - v_quota.searches_used;
      IF v_available >= p_amount THEN
        UPDATE org_quotas SET searches_used = searches_used + p_amount WHERE org_id = p_org_id;
        RETURN TRUE;
      END IF;
    WHEN 'recording' THEN
      v_available := v_quota.recordings_per_month - v_quota.recordings_used;
      IF v_available >= p_amount THEN
        UPDATE org_quotas SET recordings_used = recordings_used + p_amount WHERE org_id = p_org_id;
        RETURN TRUE;
      END IF;
    WHEN 'ai' THEN
      v_available := v_quota.ai_requests_per_month - v_quota.ai_requests_used;
      IF v_available >= p_amount THEN
        UPDATE org_quotas SET ai_requests_used = ai_requests_used + p_amount WHERE org_id = p_org_id;
        RETURN TRUE;
      END IF;
    ELSE
      RAISE EXCEPTION 'Unknown quota type: %', p_quota_type;
  END CASE;

  RETURN FALSE;
END;
$$ LANGUAGE plpgsql;

-- Function to increment quota usage directly
CREATE OR REPLACE FUNCTION increment_quota_usage(
  p_org_id UUID,
  p_field TEXT,
  p_amount INTEGER DEFAULT 1
) RETURNS VOID AS $$
BEGIN
  -- Dynamic SQL to update the specified field
  EXECUTE format(
    'UPDATE org_quotas SET %I = %I + $1 WHERE org_id = $2',
    p_field, p_field
  ) USING p_amount, p_org_id;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- ============================================
-- PARTITION INDEXES
-- ============================================

-- Add indexes to each partition explicitly (indexes aren't inherited)
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_search_analytics_2025_01_org
  ON search_analytics_2025_01(org_id, created_at DESC);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_search_analytics_2025_01_query
  ON search_analytics_2025_01 USING gin(to_tsvector('english', query));

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_search_analytics_2025_02_org
  ON search_analytics_2025_02(org_id, created_at DESC);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_search_analytics_2025_02_query
  ON search_analytics_2025_02 USING gin(to_tsvector('english', query));

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_search_analytics_2025_03_org
  ON search_analytics_2025_03(org_id, created_at DESC);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_search_analytics_2025_03_query
  ON search_analytics_2025_03 USING gin(to_tsvector('english', query));

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_search_analytics_2025_04_org
  ON search_analytics_2025_04(org_id, created_at DESC);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_search_analytics_2025_04_query
  ON search_analytics_2025_04 USING gin(to_tsvector('english', query));

-- ============================================
-- OPTIMIZED INDEXES
-- ============================================

-- Partial index for active quotas (most queries)
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_org_quotas_active
  ON org_quotas(org_id)
  WHERE quota_reset_at > now();

-- Index for quota reset check
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_org_quotas_reset
  ON org_quotas(quota_reset_at)
  WHERE quota_reset_at <= now();

-- Composite index for usage events
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_quota_events_composite
  ON quota_usage_events(org_id, quota_type, created_at DESC);

-- Index for search feedback aggregation
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_search_feedback_composite
  ON search_feedback(org_id, query, created_at DESC);

-- ============================================
-- MATERIALIZED VIEW OPTIMIZATION
-- ============================================

-- Non-blocking refresh function for materialized views
CREATE OR REPLACE FUNCTION refresh_popular_queries()
RETURNS void AS $$
BEGIN
  -- Use CONCURRENTLY to avoid locking reads
  REFRESH MATERIALIZED VIEW CONCURRENTLY popular_queries;
END;
$$ LANGUAGE plpgsql;

-- Create additional materialized view for org-level analytics
CREATE MATERIALIZED VIEW IF NOT EXISTS org_analytics_summary AS
SELECT
  org_id,
  COUNT(*) as total_searches,
  AVG(latency_ms) as avg_latency,
  PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY latency_ms) as p50_latency,
  PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY latency_ms) as p95_latency,
  SUM(CASE WHEN cache_hit THEN 1 ELSE 0 END)::FLOAT / COUNT(*) as cache_hit_rate,
  COUNT(DISTINCT user_id) as unique_users,
  DATE(created_at) as date
FROM search_analytics
WHERE created_at > now() - INTERVAL '7 days'
GROUP BY org_id, DATE(created_at);

CREATE UNIQUE INDEX IF NOT EXISTS idx_org_analytics_summary_unique
  ON org_analytics_summary(org_id, date);

-- ============================================
-- CONNECTION POOLING CONFIGURATION
-- ============================================

-- Optimize connection settings for pooling
ALTER SYSTEM SET max_connections = 200;
ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements';
ALTER SYSTEM SET pg_stat_statements.track = 'all';

-- Statement timeout for quota checks (fail fast)
CREATE OR REPLACE FUNCTION set_quota_check_timeout()
RETURNS void AS $$
BEGIN
  SET LOCAL statement_timeout = '100ms';
END;
$$ LANGUAGE plpgsql;

-- ============================================
-- BATCH OPERATIONS
-- ============================================

-- Batch insert for analytics events
CREATE OR REPLACE FUNCTION batch_insert_analytics(
  p_events JSONB
) RETURNS INTEGER AS $$
DECLARE
  v_count INTEGER := 0;
BEGIN
  INSERT INTO search_analytics (
    org_id, user_id, query, mode, results_count,
    latency_ms, cache_hit, cache_layer, filters,
    clicked_result_ids, session_id
  )
  SELECT
    (event->>'org_id')::UUID,
    (event->>'user_id')::UUID,
    event->>'query',
    event->>'mode',
    (event->>'results_count')::INTEGER,
    (event->>'latency_ms')::INTEGER,
    (event->>'cache_hit')::BOOLEAN,
    event->>'cache_layer',
    event->'filters',
    ARRAY(SELECT jsonb_array_elements_text(event->'clicked_result_ids')),
    (event->>'session_id')::UUID
  FROM jsonb_array_elements(p_events) AS event;

  GET DIAGNOSTICS v_count = ROW_COUNT;
  RETURN v_count;
END;
$$ LANGUAGE plpgsql;

-- ============================================
-- CLEANUP AND MAINTENANCE
-- ============================================

-- Function to create future partitions automatically
CREATE OR REPLACE FUNCTION create_monthly_partitions()
RETURNS void AS $$
DECLARE
  v_start_date DATE;
  v_end_date DATE;
  v_partition_name TEXT;
BEGIN
  -- Create partitions for next 3 months
  FOR i IN 1..3 LOOP
    v_start_date := date_trunc('month', now() + (i || ' months')::INTERVAL);
    v_end_date := v_start_date + INTERVAL '1 month';
    v_partition_name := 'search_analytics_' || to_char(v_start_date, 'YYYY_MM');

    -- Check if partition exists
    IF NOT EXISTS (
      SELECT 1 FROM pg_class
      WHERE relname = v_partition_name
    ) THEN
      -- Create partition
      EXECUTE format(
        'CREATE TABLE %I PARTITION OF search_analytics FOR VALUES FROM (%L) TO (%L)',
        v_partition_name, v_start_date, v_end_date
      );

      -- Create indexes on new partition
      EXECUTE format(
        'CREATE INDEX %I ON %I(org_id, created_at DESC)',
        'idx_' || v_partition_name || '_org', v_partition_name
      );

      EXECUTE format(
        'CREATE INDEX %I ON %I USING gin(to_tsvector(''english'', query))',
        'idx_' || v_partition_name || '_query', v_partition_name
      );

      RAISE NOTICE 'Created partition %', v_partition_name;
    END IF;
  END LOOP;
END;
$$ LANGUAGE plpgsql;

-- Function to drop old partitions
CREATE OR REPLACE FUNCTION drop_old_partitions()
RETURNS void AS $$
DECLARE
  v_cutoff_date DATE;
  v_partition_name TEXT;
BEGIN
  v_cutoff_date := date_trunc('month', now() - INTERVAL '6 months');

  -- Find and drop old partitions
  FOR v_partition_name IN
    SELECT tablename FROM pg_tables
    WHERE tablename LIKE 'search_analytics_%'
    AND tablename < 'search_analytics_' || to_char(v_cutoff_date, 'YYYY_MM')
  LOOP
    EXECUTE format('DROP TABLE IF EXISTS %I', v_partition_name);
    RAISE NOTICE 'Dropped old partition %', v_partition_name;
  END LOOP;
END;
$$ LANGUAGE plpgsql;

-- ============================================
-- SCHEDULED JOBS (using pg_cron if available)
-- ============================================

-- Note: Requires pg_cron extension
-- CREATE EXTENSION IF NOT EXISTS pg_cron;

-- Schedule partition maintenance (runs monthly)
-- SELECT cron.schedule('create-partitions', '0 0 1 * *', 'SELECT create_monthly_partitions()');
-- SELECT cron.schedule('drop-old-partitions', '0 1 1 * *', 'SELECT drop_old_partitions()');

-- Schedule materialized view refresh (runs every hour)
-- SELECT cron.schedule('refresh-popular-queries', '0 * * * *', 'SELECT refresh_popular_queries()');
-- SELECT cron.schedule('refresh-org-analytics', '5 * * * *', 'REFRESH MATERIALIZED VIEW CONCURRENTLY org_analytics_summary');

-- Schedule expired data cleanup (runs daily)
-- SELECT cron.schedule('cleanup-expired', '0 2 * * *', 'SELECT delete_expired_search_history()');

-- ============================================
-- MONITORING QUERIES
-- ============================================

-- Query to check quota usage efficiency
CREATE OR REPLACE VIEW quota_usage_efficiency AS
SELECT
  plan_tier,
  COUNT(*) as org_count,
  AVG(searches_used::FLOAT / NULLIF(searches_per_month, 0)) as avg_search_usage,
  AVG(recordings_used::FLOAT / NULLIF(recordings_per_month, 0)) as avg_recording_usage,
  AVG(ai_requests_used::FLOAT / NULLIF(ai_requests_per_month, 0)) as avg_ai_usage,
  AVG(storage_used_gb / NULLIF(storage_gb, 0)) as avg_storage_usage
FROM org_quotas
GROUP BY plan_tier;

-- Query to identify slow queries
CREATE OR REPLACE VIEW slow_queries AS
SELECT
  query,
  calls,
  mean_exec_time,
  max_exec_time,
  total_exec_time,
  stddev_exec_time
FROM pg_stat_statements
WHERE query NOT LIKE '%pg_stat_statements%'
ORDER BY mean_exec_time DESC
LIMIT 20;

-- ============================================
-- GRANTS
-- ============================================

-- Ensure proper permissions for service role
GRANT EXECUTE ON FUNCTION check_quota_optimized TO service_role;
GRANT EXECUTE ON FUNCTION increment_quota_usage TO service_role;
GRANT EXECUTE ON FUNCTION batch_insert_analytics TO service_role;
GRANT EXECUTE ON FUNCTION create_monthly_partitions TO service_role;
GRANT EXECUTE ON FUNCTION refresh_popular_queries TO service_role;